---
title: "Random Forest"
format: 
  html:
    theme: cosmo
    smooth-scroll: true
    toc: true
    toc-location: right
    # self-contained: true
# author: 
#     - name: J.I. Seo
#       affiliations:
#       - Gyeongguk National University
#     - name: J.W. Lee
#       # affiliations:
#       # - University of Missouri
      
number-sections: true
highlight-style: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(width=200)
```

> 실습 자료 : 1912년 4월 15일 타이타닉호 침몰 당시 탑승객들의 정보를 기록한 데이터셋이며, 총 11개의 변수를 포함하고 있다. 이 자료에서 **Target**은 `Survived`이다.

<center>![](./image/그림_titanic.png)</center>

<br />

<center><img src="./image/Titanic_표.png" width="400" height="400"></center>

<br />



## 데이터 불러오기


```{r, eval=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr", "tidyr",
               "ggplot2", "GGally",
               "caret",
               "doParallel", "parallel")                                 # For 병렬 처리

registerDoParallel(cores=detectCores())                                  # 사용할 Core 개수 지정     

titanic <- fread("../Titanic.csv")                                       # 데이터 불러오기

titanic %>%
  as_tibble
```

```{r, echo=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr", "tidyr",
               "ggplot2", "GGally",
               "caret",
               "doParallel", "parallel")                                 # For 병렬 처리

registerDoParallel(cores=detectCores())                                  # 사용할 Core 개수 지정     

titanic <- fread(paste(getwd(), "/DATA/Titanic.csv", sep = "/"))               # 데이터 불러오기

titanic %>%
  as_tibble
```

## 데이터 전처리 I

```{r}
titanic %<>%
  data.frame() %>%                                                      # Data Frame 형태로 변환 
  mutate(Survived = ifelse(Survived == 1, "yes", "no"))                 # Target을 문자형 변수로 변환

# 1. Convert to Factor
fac.col <- c("Pclass", "Sex",
             # Target
             "Survived")

titanic <- titanic %>% 
  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환

glimpse(titanic)                                                        # 데이터 구조 확인

# 2. Generate New Variable
titanic <- titanic %>%
  mutate(FamSize = SibSp + Parch)                                       # "FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수"로 가족 수를 의미하는 새로운 변수

glimpse(titanic)                                                        # 데이터 구조 확인

# 3. Select Variables used for Analysis
titanic1 <- titanic %>% 
  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택

glimpse(titanic1)                                                       # 데이터 구조 확인
```

## 데이터 탐색

```{r}
ggpairs(titanic1,                                        
        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현
  theme_bw()

ggpairs(titanic1,                                     
        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("#00798c", "#d1495b")) + # 특정 색깔 지정
  scale_fill_manual(values = c("#00798c", "#d1495b")) +   # 특정 색깔 지정
  theme_bw()
```

## 데이터 분할

```{r}
# Partition (Training Dataset : Test Dataset = 7:3)
y      <- titanic1$Survived                           # Target

set.seed(200)
ind    <- createDataPartition(y, p = 0.7, list  =T)   # Index를 이용하여 7:3으로 분할
titanic.trd <- titanic1[ind$Resample1,]               # Training Dataset
titanic.ted <- titanic1[-ind$Resample1,]              # Test Dataset
```


## 데이터 전처리 II

```{r}
# Imputation
titanic.trd.Imp <- titanic.trd %>% 
  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체

titanic.ted.Imp <- titanic.ted %>% 
  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체

glimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인
glimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인
```


## 모형 훈련

Bagging은 "Bootstrap Aggregation"의 약어로써 Original Dataset으로부터 크기가 동일한 Bootstrap Dataset을 생성한 후 각 Dataset에 독립적으로 예측 모형을 적용하고, 예측 결과를 집계하여 최종 예측을 도출한다. Bagging은 여러 모형의 예측 결과를 집계함으로써 예측 성능을 향상시키는 앙상블 기법이다.

<center>
![](./image/Bagging.png){width=70%}
</center>

</br>


Random Forest는 Bagging 기법을 사용하는 대표적인 머신러닝 알고리듬으로 Original Dataset으로부터 크기가 동일한 Bootstrap Dataset을 생성한 후 각 Dataset에 독립적으로 의사결정나무(Decision Tree)를 적용한다. Random Forest의 가장 큰 특징은 노드를 분할할 때마다 $m$개의 예측 변수(Feature)를 랜덤하게 추출하고 그중 최적의 변수의 선택한다. 이러한 랜덤성은 생성된 트리들의 상관성을 낮춤으로써 성능을 더욱 향상시키는 역할을 한다.

<center>
![](./image/rf.png){width=70%}
</center>

</br>


Package `"caret"`은 통합 API를 통해 R로 기계 학습을 실행할 수 있는 매우 실용적인 방법을 제공한다. Package `"caret"`에서는 초모수의 최적의 조합을 찾는 방법으로 그리드 검색(Grid Search), 랜덤 검색(Random Search), 직접 탐색 범위 설정이 있다. 여기서는 초모수 `mtry`의 최적값을 찾기 위해 그리드 검색을 수행하였고, 이를 기반으로 직접 탐색 범위를 설정하였다. 아래는 그리드 검색을 수행하였을 때 결과이다.

```{r}
fitControl <- trainControl(method = "cv", number = 5, # 5-Fold Cross Validation (5-Fold CV)
                           allowParallel = TRUE)      # 병렬 처리

set.seed(200)                                         # For CV
rf.fit <- train(Survived ~ ., data = titanic.trd.Imp, 
                trControl = fitControl ,
                method = "parRF",
                ntree = 100,                          # 생성할 트리 개수
                importance = TRUE)                    # 예측 변수의 중요도 저장
```

`Caution!` Package `"caret"`을 통해 Random Forest를 수행하기 위해서 함수 `train()`의 옵션 `method = "parRF"` 또는 `method = "rf"`를 입력할 수 있다. 전자의 경우 병렬 처리를 통해 더 빠르게 모형 훈련을 수행할 수 있지만 OBB 오차는 계산할 수 없다. 게다가, 함수 `train(Target ~ 예측 변수, data)`를 사용하면 범주형 예측 변수는 자동적으로 더미 변환을 수행한다. 범주형 예측 변수에 대해 더미 변환을 수행하고 싶지 않다면 함수 `train(x = 예측 변수만 포함하는 데이터셋, y = Target만 포함하는 데이터셋)`를 사용한다.     

```{r}
rf.fit

plot(rf.fit)                                          # Plot
```

`Result!` 랜덤하게 결정된 3개의 `mtry` 값에 대한 정확도를 보여주며, `mtry` = 2일 때 정확도가 가장 높은 것을 알 수 있다. 따라서 그리드 검색을 통해 찾은 최적의 초모수 값 2 근처의 값들을 탐색 범위로 설정하여 훈련을 다시 수행할 수 있다.


```{r}
customGrid <- expand.grid(mtry = seq(1, 5, by = 1))   # mtry의 탐색 범위 

set.seed(200)                                         # For CV
rf.tune.fit <- train(Survived ~ ., data = titanic.trd.Imp, 
                     trControl = fitControl,
                     method = "parRF", 
                     tuneGrid = customGrid,
                     ntree = 100,                     # 생성할 트리 개수
                     importance = TRUE)               # 예측 변수의 중요도 저장

rf.tune.fit

plot(rf.tune.fit)                                     # Plot

rf.tune.fit$bestTune                                  # mtry의 최적값
```

`Result!` `mtry` = 2일 때 정확도가 가장 높다는 것을 알 수 있으며, `mtry` = 2를 가지는 모형을 최적의 훈련된 모형으로 선택한다.

```{r}
# 변수 중요도
randomForest::varImpPlot(rf.tune.fit$finalModel)
```

`Result!` 정확도와 지니계수 측면에서 `Sexmale`이 Target `Survived`을 분류하는 데 있어 중요하다.


## 모형 평가

`Caution!` 모형 평가를 위해 `Test Dataset`에 대한 `예측 class/확률` 이 필요하며, 함수 `predict()`를 이용하여 생성한다. 
```{r}
# 예측 class 생성 
test.rf.class <- predict(rf.tune.fit,
                         newdata = titanic.ted.Imp[,-1]) # Test Dataset including Only 예측 변수     

test.rf.class %>%
  as_tibble
```

<br />

### ConfusionMatrix

```{r}
CM   <- caret::confusionMatrix(test.rf.class, titanic.ted.Imp$Survived, 
                               positive = "yes")        # confusionMatrix(예측 class, 실제 class, positive = "관심 class")
CM
```

<br />

### ROC 곡선

```{r}
# 예측 확률 생성
test.rf.prob <- predict(rf.tune.fit, 
                        newdata = titanic.ted.Imp[,-1], # Test Dataset including Only 예측 변수  
                        type = "prob")                  # 예측 확률 생성     

test.rf.prob %>%
  as_tibble
```

```{r}
test.rf.prob <- test.rf.prob[,2]                        # "Survived = yes"에 대한 예측 확률

ac  <- titanic.ted.Imp$Survived                         # Test Dataset의 실제 class 
pp  <- as.numeric(test.rf.prob)                         # 예측 확률을 수치형으로 변환
```

#### Package "pROC"

```{r}
pacman::p_load("pROC")

rf.roc  <- roc(ac, pp, plot = T, col = "gray")         # roc(실제 class, 예측 확률)
auc     <- round(auc(rf.roc), 3)
legend("bottomright", legend = auc, bty = "n")
```

`Caution!` Package `"pROC"`를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.

```{r}
# 함수 plot.roc() 이용
plot.roc(rf.roc,   
         col="gray",                                   # Line Color
         print.auc = TRUE,                             # AUC 출력 여부
         print.auc.col = "red",                        # AUC 글씨 색깔
         print.thres = TRUE,                           # Cutoff Value 출력 여부
         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양
         print.thres.col = "red",                      # Cutoff Value를 표시하는 도형의 색깔
         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부
         auc.polygon.col = "gray90")                   # 곡선 아래 면적의 색깔
```


```{r}
# 함수 ggroc() 이용
ggroc(rf.roc) +
annotate(geom = "text", x = 0.9, y = 1.0,
label = paste("AUC = ", auc),
size = 5,
color="red") +
theme_bw()
```



#### Package "Epi"

```{r}
pacman::p_load("Epi")       
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp, ac, plot = "ROC")                              # ROC(예측 확률, 실제 class)  
```

#### Package "ROCR"

```{r}
pacman::p_load("ROCR")

rf.pred <- prediction(pp, ac)                          # prediction(예측 확률, 실제 class) 

rf.perf <- performance(rf.pred, "tpr", "fpr")          # performance(, "민감도", "1-특이도")                      
plot(rf.perf, col = "gray")                            # ROC Curve

perf.auc   <- performance(rf.pred, "auc")              # AUC
auc        <- attributes(perf.auc)$y.values
legend("bottomright", legend = auc, bty = "n")
```

<br />

### 향상 차트

#### Package "ROCR"

```{r}
rf.perf <- performance(rf.pred, "lift", "rpp")         # Lift Chart                      
plot(rf.perf, main = "lift curve",
     colorize = T,                                     # Coloring according to cutoff 
     lwd = 2) 
```


```{r, eval=F, echo=F, include=FALSE}
#### **2) Package "lift"**

pacman::p_load("lift")

ac.numeric <- ifelse(titanic.ted.Imp$Survived == "yes", 1, 0)         # Target을 수치형으로 변환

plotLift(test.svm.prob, ac.numeric, cumulative = T, n.buckets = 24)   # plotLift(7-2에서 생성한 예측 확률, 실제 class)
TopDecileLift(test.svm.prob, ac.numeric)		                          # Top 10%의 향상도 출력
```
